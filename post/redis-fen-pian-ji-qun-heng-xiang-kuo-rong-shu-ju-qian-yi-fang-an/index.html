<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>redis分片集群横向扩容数据迁移方案 | One-Piece</title>
<link rel="shortcut icon" href="https://onepiece-dz.github.io/favicon.ico?v=1596420241811">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://onepiece-dz.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="redis分片集群横向扩容数据迁移方案 | One-Piece - Atom Feed" href="https://onepiece-dz.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="背景
我们知道，在分布式系统中，用于解决客户端访问分布式集群热点问题的算法比较出名的一种算法就是一致性哈希算法，该算法同样应用在redis中，本司所使用的是64位的有符号hash算法（网上很多例子所使用的是32位无符号hash），加上虚拟节..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://onepiece-dz.github.io">
  <img class="avatar" src="https://onepiece-dz.github.io/images/avatar.png?v=1596420241811" alt="">
  </a>
  <h1 class="site-title">
    One-Piece
  </h1>
  <p class="site-description">
    知行合一
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
      
        <a href="/post/java" class="menu">
          java
        </a>
      
    
      
        <a href="/post" class="menu" target="_blank">
          flink
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              redis分片集群横向扩容数据迁移方案
            </h2>
            <div class="post-info">
              <span>
                2020-08-02
              </span>
              <span>
                5 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="背景">背景</h1>
<p>我们知道，在分布式系统中，用于解决客户端访问分布式集群热点问题的算法比较出名的一种算法就是一致性哈希算法，该算法同样应用在redis中，本司所使用的是64位的有符号hash算法（网上很多例子所使用的是32位无符号hash），加上虚拟节点解决哈希倾斜问题。但无论一致性哈希算法如何优秀，它依然解决不了新增删除节点带来的数据迁移需求。（虽然在很多分布式缓存应用场景，可能仅仅只是存储热点数据，不需要考虑数据迁移，但考虑到热点命中率带来的影响，也是需要进行数据迁移的）。</p>
<h1 id="方案一离线迁移方案">方案一：离线迁移方案</h1>
<p><strong>dump---拷贝到中转机---合并dump---清理冗余数据---拆分dump---传dump---停起主从----启动主从加载数据</strong></p>
<p><strong>优点</strong>：整个迁移过程，只有最终起停主从加载数据时，无法提供服务，大概持续几分钟的时间，应用系统可以通过降级服务的方式避免这种影响；<br>
<strong>缺点</strong>：从dump开始之后的新数据都将丢失，而且服务起停过程期间产生的数据如果应用系统自己不做实时备份，将永久丢失。</p>
<p><strong>应用场景</strong>：对数据丢失不敏感，支持降级的服务，以及有紧急扩容需求的业务系统可以选择</p>
<h1 id="方案二不停机横向扩容方案1">方案二：不停机横向扩容方案1</h1>
<p><strong>第一步</strong>：运维dump老分片的rdb文件（此时刻为T1），遍历文件内容，按照新分片进行rehash，如果发现rehash之后匹配的分片与之前不一致，则为需要迁移的key，记录迁移前的分片（用于删除），记录迁移后的分片（用于迁移）；<br>
<strong>第二步</strong>：将需要迁移的key使用redis客户端插入到新的分片（第二步中已经通过rehash计算出来新的所属分片）；<br>
<strong>第三步</strong>：应用系统替换最新的redis分片配置，此时新数据将按照新的分片进行路由（此时刻为T2）；<br>
<strong>第四步</strong>：从老分片中删除这部分已经迁移的key（第二步中已经比较出这部分key；<br>
<strong>第五步</strong>：重复第一步、第二步、第四步，目的是将T1-T2时刻写入到老分片集群的新数据重新迁移；<br>
（注：第二步，第四步操作的数据是同一批，都是第一步计算出来的需要重新迁移的key；需要直接使用插入删除命令）</p>
<p><strong>优点</strong>：整个迁移过程不需要停机，数据不会丢失；<br>
<strong>缺点</strong>：<br>
1.第三步执行成功之前，这部分迁移的key会因为客户端rehash结果与之前不一致导致查询不到，此时可能会影响业务；（该方案需要业务自行评估影响）；<br>
2.步骤三插入前可能已经在新分片有写入了，这时候旧数据不能随便写入，可能引起数据覆盖，这个需要做检查优化。实现较为繁琐。</p>
<p><strong>应用场景</strong>：对数据丢失敏感，但可支持短时间降级（key查询为空的情况）的服务，以及有紧急扩容需求的业务系统可以选择；</p>
<h1 id="方案三不停机横向扩容方案2">方案三：不停机横向扩容方案2</h1>
<p>应用系统同时对新老分片集群进行“双份”写入，此时查询还是通过老分片提供；<br>
等到新分片集群已经完全可以提供查询服务时，替换查询服务到新分片集群（如何确认新分片集群可以提供查询服务，需要根据老集群中所有key的最长失效时间，必须超过这个时间，才能将查询切换到新集群；</p>
<p><strong>优点</strong>：整个迁移过程不需要停机，数据不会丢失，同时迁移过程也不会出现查询不到key的情况；<br>
<strong>缺点</strong>：<br>
1.需要应用系统自行改造代码发布，迁移完之后，还需要进行发布还原代码；<br>
2.整个迁移过程可能会因为集群中key的最长失效时间过长，导致迁移周期太长，同时迁移过程可能出现大量key在不同的分片中重复存储，因此这个方案在时间和空间上都步不适合临时紧急扩容；<br>
3.“双份”写入可能会影响服务性能<br>
<strong>应用场景</strong>：对数据丢失敏感，且不支持服务降级的系统，以及没有紧急扩容要求的系统可以选择；</p>
<p><strong>总结：每个方案各有优缺点，业务系统可以根据自身的应用场景和数据特点选择方案。方案一和方案二都需要中间件和运维进行技术支持，应用系统不用做改造。方案二目前尚未提供；方案三不需要中间件和运维支持，业务系统自行完成；方案一可以有改进版，业务系统自行备份迁移过程的数据，在迁移完成后自行步入。</strong></p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#%E8%83%8C%E6%99%AF">背景</a></li>
<li><a href="#%E6%96%B9%E6%A1%88%E4%B8%80%E7%A6%BB%E7%BA%BF%E8%BF%81%E7%A7%BB%E6%96%B9%E6%A1%88">方案一：离线迁移方案</a></li>
<li><a href="#%E6%96%B9%E6%A1%88%E4%BA%8C%E4%B8%8D%E5%81%9C%E6%9C%BA%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%E6%96%B9%E6%A1%881">方案二：不停机横向扩容方案1</a></li>
<li><a href="#%E6%96%B9%E6%A1%88%E4%B8%89%E4%B8%8D%E5%81%9C%E6%9C%BA%E6%A8%AA%E5%90%91%E6%89%A9%E5%AE%B9%E6%96%B9%E6%A1%882">方案三：不停机横向扩容方案2</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://onepiece-dz.github.io/post/about/">
              <h3 class="post-title">
                关于
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'c1cd96b713d8487407c2',
    clientSecret: 'c0321530de2e8cfb94c7acf916a996cebafb006d',
    repo: 'onepiece-dz.github.io',
    owner: 'onepiece-dz',
    admin: ['onepiece-dz'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://onepiece-dz.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
